{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63e5b80b-64fb-47b5-85e6-999722280216",
   "metadata": {},
   "source": [
    "# On-Cloud Data Retrieval and Analysis: Aboveground biomass from GEDI, ICESat-2 and Field Data\n",
    "## Overview\n",
    "This tutorial will demonstrate how to directly access and retrieve the GEDI dataset, ICESat-2 and Field Data in the cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a3df98-b4d0-463a-ba20-12116c9c75b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import earthaccess\n",
    "import s3fs\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from harmony import BBox, Client, Collection, Request, LinkType\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import ListedColormap\n",
    "sns.set(style='whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4928a36c-c873-4a7c-a0dd-57199d484d61",
   "metadata": {},
   "source": [
    "## Area of interest\n",
    "We will use a boundary of the [Reserva Florestal Adolpho Ducke](https://ppbio.inpa.gov.br/en/Sites/RFAD), as the region of interest. Reserva Adolpho Ducke is a 10,000-hectare (25,000-acre) protected area of the Amazon rainforest on the outskirts of the city of Manaus, Brazil. It is a part of long term ecological research network and is one of the most intensively studied rainforest in the world.\n",
    "\n",
    "The boundary file is provided as a GeoJSON file at `polygons/reserva_ducke.json`. Let’s open and plot this file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379df806-cf96-4f00-a129-3812651d47d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# esri background basemap for maps\n",
    "xyz = \"https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}\"\n",
    "attr = \"ESRI\"\n",
    "poly_json = 'polygons/reserva_ducke.json'\n",
    "poly = gpd.read_file(poly_json) \n",
    "poly.explore(color='red', fill=False, tiles=xyz, attr=attr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ffecb6-3c91-4b85-a396-6b140f4c0b08",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "- Dubayah, R.O., J. Armston, J.R. Kellner, L. Duncanson, S.P. Healey, P.L. Patterson, S. Hancock, H. Tang, J. Bruening, M.A. Hofton, J.B. Blair, and S.B. Luthcke. 2022. GEDI L4A Footprint Level Aboveground Biomass Density, Version 2.1. ORNL DAAC, Oak Ridge, Tennessee, USA. https://doi.org/10.3334/ORNLDAAC/2056\n",
    "- Neuenschwander, A. L., Pitts, K. L., Jelley, B. P., Robbins, J., Markel, J., Popescu, S. C., Nelson, R. F., Harding, D., Pederson, D., Klotz, B. & Sheridan, R. (2023). ATLAS/ICESat-2 L3A Land and Vegetation Height. (ATL08, Version 6). [Data Set]. Boulder, Colorado USA. NASA National Snow and Ice Data Center Distributed Active Archive Center. https://doi.org/10.5067/ATLAS/ATL08.006.\n",
    "- dos-Santos, M.N., M.M. Keller, E.R. Pinage, and D.C. Morton. 2022. Forest Inventory and Biophysical Measurements, Brazilian Amazon, 2009-2018. ORNL DAAC, Oak Ridge, Tennessee, USA. https://doi.org/10.3334/ORNLDAAC/2007\n",
    "\n",
    "## Workflow\n",
    "```mermaid\n",
    "erDiagram\n",
    "    ORNL_DAAC {\n",
    "        S3-bucket ornl-cumulus-prod-protected\n",
    "    }\n",
    "    NSIDC_DAAC {\n",
    "        S3-bucket nsidc-cumulus-prod-protected\n",
    "    }\n",
    "    Forest_Inventory_Brazil {\n",
    "        Instrument Field_Measurement\n",
    "    }\n",
    "    GEDI04_A {\n",
    "        Instrument GEDI \n",
    "    }\n",
    "    ATL08 {\n",
    "        Instrument ICESaT-2\n",
    "    }\n",
    "    Harmony {\n",
    "        Type Service\n",
    "        S3-bucket harmony-prod-staging\n",
    "    }\n",
    "    Earthaccess {\n",
    "        Type Tool\n",
    "    }\n",
    "    ORNL_DAAC||..||Forest_Inventory_Brazil: \"\"\n",
    "    ORNL_DAAC||..||GEDI04_A: \"\"\n",
    "    NSIDC_DAAC||..||ATL08: \"\"\n",
    "    ATL08||..||Harmony: \"trajectory subsetter\"\n",
    "    GEDI04_A||..||Harmony: \"trajectory subsetter\"\n",
    "    Forest_Inventory_Brazil ||..||Earthaccess: \"direct access\"\n",
    "    Harmony||--o{ \"JupyterHub\" : \"direct access\"\n",
    "    Earthaccess||--o{ \"JupyterHub\" : \"direct access\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58135efc-c6f4-4899-b690-299c57d60355",
   "metadata": {},
   "source": [
    "## Earthdata Authentication\n",
    "We recommend authenticating your Earthdata Login (EDL) information using the earthaccess python library as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23360f27-9206-42e3-8d44-5323bb0303bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = earthaccess.login(strategy=\"netrc\") # works if the EDL login already been persisted to a netrc\n",
    "if not auth.authenticated:\n",
    "    # ask for EDL credentials and persist them in a .netrc file\n",
    "    auth = earthaccess.login(strategy=\"interactive\", persist=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd2ad43-a4af-4e10-9781-8b84dd21a19b",
   "metadata": {},
   "source": [
    "## 1. Plot-level Forest Inventory Data\n",
    "```mermaid\n",
    "erDiagram\n",
    "    ORNL_DAAC {\n",
    "        S3-bucket ornl-cumulus-prod-protected\n",
    "    }\n",
    "    Forest_Inventory_Brazil {\n",
    "        Instrument Field_Measurement\n",
    "    }\n",
    "    Earthaccess {\n",
    "        Type Tool\n",
    "    }\n",
    "    ORNL_DAAC||..||Forest_Inventory_Brazil: \"\"\n",
    "    Forest_Inventory_Brazil||..||Earthaccess: \"direct access\"\n",
    "    Earthaccess||--o{ \"JupyterHub\" : \"direct access\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e68e78-424b-40a2-9f9a-75bc21a8cff9",
   "metadata": {},
   "source": [
    "### 1a. Search data files\n",
    "We will use the `earthaccess` module to search for dataset granules.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a79aba-531b-4274-b3e3-3988bbdd1af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CMS Brazil field dataset\n",
    "doi = '10.3334/ORNLDAAC/2007'\n",
    "# searching files\n",
    "granules = earthaccess.search_data(\n",
    "    doi=doi, # dataset doi\n",
    "    granule_name = \"*.csv\",\n",
    "    bounding_box = tuple(poly.total_bounds.tolist()),\n",
    "    cloud_hosted = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60123a6c-f4d5-4de1-9f0d-3b4cf0e941c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print s3 links\n",
    "[g.data_links(access=\"direct\")[0] for g in granules]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea592314-a3e2-4986-941e-038183a7da97",
   "metadata": {},
   "source": [
    "Of the two datasets found, we will retrieve the 2016 inventory which is closer to the GEDI and ICESat-2 temporal range. The Forest Inventory Adolpho Ducke Forest Reserve II (DUC_A01_2016_Inventory) was carried out in Adolpho Ducke Forest Reserve, Amazonas, Brazil. A total of 17 50x50m plots were measured in 2016. Trees with diameter at breast height (DBH) equal to or greater than 35cm were accounted for and measured within the plot area whereas trees with DBH equal to or greater than 10cm were only measured within the subplot area.\n",
    "\n",
    "### 1b. Open and plot the data file\n",
    "Let's open the granule (s3 object) into a xarray. The `earthaccess` module manages temporary authentication needed for accessing data in NASA's Earthdata cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f94e1cf-74cd-4ae1-afc5-ef90e198de86",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fh in earthaccess.open(granules):\n",
    "    if fh.granule.data_links()[0].endswith(\"2016_Inventory.csv\"):\n",
    "        field_df = pd.read_csv(fh, encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df89a797-ae5b-45e1-89df-5fddf8edba87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing the dataframe\n",
    "field_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76804e55-3447-405e-8ae3-e3887a8a0d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot tree locations on a map\n",
    "field_gdf = gpd.GeoDataFrame(field_df, crs=\"EPSG:4326\",\n",
    "                       geometry=gpd.points_from_xy(field_df[\"UTM.Northing\"],\n",
    "                                                   field_df[\"UTM.Easting\"]))\n",
    "m = field_gdf.explore(column='plot', cmap='tab20', legend=None, tiles=xyz, attr=attr)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce88a63-840c-46d4-a68d-6019b13a3305",
   "metadata": {},
   "source": [
    "### 1c. Compute aboveground biomass\n",
    "We will be using the allometry for the tropical forest from [Chave et al. 2005](https://doi.org/10.1007/s00442-005-0100-x) and wood specific gravity for central Amazon obtained from [Chave et al. 2006](https://doi.org/10.1890/1051-0761(2006)016[2356:RAPVOW]2.0.CO;2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c202257a-8d78-41ac-a158-a6403d2533d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying allometry\n",
    "field_df['AGB_kg']=0.0509*0.652*((field_df.DBH)**2)*(field_df.Htotc)\n",
    "# computing total agb\n",
    "total_agb = field_df.groupby(['plot'])['AGB_kg'].sum().reset_index()\n",
    "# computing agbd in Mgha-1\n",
    "total_agb['AGBD']=total_agb['AGB_kg']/(0.25*1000)\n",
    "# plotting agbd\n",
    "\n",
    "fig = plt.figure(figsize=(15,5))\n",
    "ax1 = fig.add_subplot(1, 3, 1)\n",
    "sns.histplot(ax=ax1, data=total_agb, y=\"AGBD\", binwidth=20, kde=True, stat='percent')\n",
    "ax1.set(ylabel=\"AGBD (Mg/ha)\", \n",
    "       title=f\"Field Plot AGBD estimates\")\n",
    "ax1.set(ylim=(0, 500))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bfb92b-5a0e-4fe1-8ff4-342118946a34",
   "metadata": {},
   "source": [
    "## 2. GEDI L4A Biomass\n",
    "```mermaid\n",
    "erDiagram\n",
    "    ORNL_DAAC {\n",
    "        S3-bucket ornl-cumulus-prod-protected\n",
    "    }\n",
    "    GEDI04_A {\n",
    "        Instrument GEDI \n",
    "    }\n",
    "    Harmony {\n",
    "        Type Service\n",
    "        S3-bucket harmony-prod-staging\n",
    "    }\n",
    "    ORNL_DAAC||..||GEDI04_A: \"\"\n",
    "    GEDI04_A||..||Harmony: \"trajectory subsetter\"\n",
    "    Harmony||--o{ \"JupyterHub\" : \"direct access\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc5455f-5148-4c14-ae9e-2b241aded5e8",
   "metadata": {},
   "source": [
    "### 2a. Define Harmony Request Parameters\n",
    "\n",
    "Let’s create a Harmony Collection object with the concept_id retrieved above. We will also define the GEDI L4A variables of interest and temporal range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff932774-9cca-45fb-947f-a9726209544a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gedi_vars(variables):\n",
    "    # gedi beams\n",
    "    beams = ['BEAM0000', 'BEAM0001', 'BEAM0010', 'BEAM0011', 'BEAM0101', 'BEAM0110', 'BEAM1000', 'BEAM1011']\n",
    "    # combine variables and beam names\n",
    "    return [f'/{b}/{v}' for b in beams for v in variables]\n",
    "\n",
    "# gedi variables\n",
    "variables_l4a = create_gedi_vars(['agbd', 'l4_quality_flag', 'land_cover_data/pft_class'])\n",
    "\n",
    "# bounding box\n",
    "b = field_gdf.total_bounds\n",
    "bounding_box = BBox(w=b[0], s=b[1], e=b[2], n=b[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c87f1a5-eac5-45d8-8aed-ebbd169b4f28",
   "metadata": {},
   "source": [
    "### 2b. Create and Submit Harmony Request\n",
    "Now, we can create a Harmony request with variables, temporal range, and bounding box and submit the request using the Harmony client object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c88daf-c71e-4a67-8421-783a9d0a3347",
   "metadata": {},
   "outputs": [],
   "source": [
    "doi = '10.3334/ORNLDAAC/2056' # GEDI L4A DOI\n",
    "\n",
    "# harmony client\n",
    "harmony_client = Client()\n",
    "# concept id\n",
    "concept_id = earthaccess.search_datasets(doi=doi, \n",
    "                                         cloud_hosted= True)[0].concept_id()\n",
    "# define harmony collection\n",
    "collection = Collection(id=concept_id)\n",
    "# define harmony request\n",
    "request = Request(collection=collection, \n",
    "              variables=variables_l4a, \n",
    "              spatial=bounding_box,\n",
    "              ignore_errors=True)\n",
    "# submit harmony request, will return job id\n",
    "subset_job_id = harmony_client.submit(request)\n",
    "# retrieve results in-region\n",
    "results_l4a = harmony_client.result_urls(subset_job_id, \n",
    "                                         show_progress=True,\n",
    "                                         link_type=LinkType.s3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b40cb5d-0054-4e75-983c-6c1d7eaddb2c",
   "metadata": {},
   "source": [
    "A temporary S3 Credentials is needed for read-only, same-region (`us-west-2`), direct access to S3 objects on the Earthdata cloud. We will use the credentials from the `harmony_client` and pass the credentials to [S3Fs class](https://s3fs.readthedocs.io/) S3FileSystem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6451b5c3-f3c6-45e7-82c6-45ac49bf1cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "creds = harmony_client.aws_credentials()\n",
    "s3 = s3fs.S3FileSystem(anon=False,\n",
    "                       key=creds['aws_access_key_id'],\n",
    "                       secret=creds['aws_secret_access_key'],\n",
    "                       token=creds['aws_session_token'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7ac186-6938-4584-9adc-bb4a7dbecd5c",
   "metadata": {},
   "source": [
    "### 2c. Read Subset files\n",
    "Let’s direct access the subsetted `h5` files and retrieve its values into the pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cef066-43c2-4718-90df-98db942bf4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_gedi_vars(beam):\n",
    "    \"\"\"reads through gedi variable hierarchy\"\"\"\n",
    "    col_names = []\n",
    "    col_val = []\n",
    "    # read all variables\n",
    "    for key, value in beam.items():\n",
    "        # check if the item is a group\n",
    "        if isinstance(value, h5py.Group):\n",
    "            # looping through subgroups\n",
    "            for key2, value2 in value.items():\n",
    "                col_names.append(key2)\n",
    "                col_val.append(value2[:].tolist())\n",
    "        else:\n",
    "            col_names.append(key)\n",
    "            col_val.append(value[:].tolist())\n",
    "    return col_names, col_val\n",
    "\n",
    "\n",
    "# define an empty pandas dataframe\n",
    "gedi_df = pd.DataFrame()\n",
    "# loop through the Harmony results\n",
    "for s3_url in results_l4a:\n",
    "    with s3.open(s3_url, mode='rb') as fh:\n",
    "        with h5py.File(fh) as hf:\n",
    "            for v in list(hf.keys()):\n",
    "                if v.startswith('BEAM'):\n",
    "                    c_n, c_v = read_gedi_vars(hf[v])\n",
    "                    # Appending to the subset_df dataframe\n",
    "                    gedi_df = pd.concat([gedi_df, \n",
    "                                         pd.DataFrame(map(list, zip(*c_v)), columns=c_n)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f6793a-2522-4852-bc9e-ca91fc802fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gedi_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1420221c-61de-4de6-8fb1-6a0bdf04f277",
   "metadata": {},
   "source": [
    "### 2d. Quality Filter and Plot\n",
    "We can now quality filter the dataset and only retrieve the good quality shots for trees and shrub cover plant functional types (PFTs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafabf3d-8844-4cbf-b518-2366738c0dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicate columns if any\n",
    "gedi_df = gedi_df.loc[:,~gedi_df.columns.duplicated()].copy()\n",
    "# converting to geojson\n",
    "gedi_gdf = gpd.GeoDataFrame(gedi_df, \n",
    "                                geometry=gpd.points_from_xy(gedi_df.lon_lowestmode, \n",
    "                                                            gedi_df.lat_lowestmode),\n",
    "                                crs=\"EPSG:4326\")\n",
    "# creating mask with good quality shots and trees/shrubs pft class\n",
    "mask = (gedi_gdf['l4_quality_flag']==1) & (gedi_gdf['pft_class'] <= 5 )\n",
    "# plotting\n",
    "gedi_gdf = gedi_gdf[['lat_lowestmode', 'lon_lowestmode', 'pft_class', 'agbd', 'geometry']]\n",
    "gedi_gdf[mask].explore(\"agbd\", m=m, vmax=500, cmap = \"YlGn\", alpha=0.5, \n",
    "                       radius=10, legend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6995e4-b58a-4142-b842-4ae5cc5bad1c",
   "metadata": {},
   "source": [
    "As we see above, the PFT of the GEDI shots in the area is classed as `2` or \"Evergreen Broadleaf Trees\". We will plot the distribution of the AGBD for good quality shots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c745f1-b587-4de6-95b1-dc128568c365",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,5))\n",
    "ax1 = fig.add_subplot(1, 3, 1)\n",
    "sns.histplot(ax=ax1, data=total_agb, y=\"AGBD\", binwidth=20, kde=True, stat='percent')\n",
    "ax1.set(ylabel=\"AGBD (Mg / ha)\", ylim=(0, 500),\n",
    "       title=\"Field Plot AGBD estimates\")\n",
    "ax2 = fig.add_subplot(1, 3, 2)\n",
    "sns.histplot(ax=ax2, data=gedi_gdf[mask], binwidth=20, y=\"agbd\", kde=True, stat='percent') \n",
    "ax2.set(ylabel=\"AGBD (Mg / ha)\", ylim=(0, 500),\n",
    "       title=\"GEDI L4A AGBD estimates\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088d631c-edef-4f69-876f-1805477cf82f",
   "metadata": {},
   "source": [
    "## 3. ICESat-2 ATL08\n",
    "```mermaid\n",
    "erDiagram\n",
    "    NSIDC_DAAC {\n",
    "        S3-bucket nsidc-cumulus-prod-protected\n",
    "    }\n",
    "    ATL08 {\n",
    "        Instrument ICESaT-2\n",
    "    }\n",
    "    Harmony {\n",
    "        Type Service\n",
    "        S3-bucket harmony-prod-staging\n",
    "    }\n",
    "    NSIDC_DAAC||..||ATL08: \"\"\n",
    "    ATL08||..||Harmony: \"trajectory subsetter\"\n",
    "    Harmony||--o{ \"JupyterHub\" : \"direct access\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6efb7b3-8b75-49c7-b146-71d769f3b9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "doi_atl08 = '10.5067/ATLAS/ATL08.006' # ICESat-2 ATL08 DOI\n",
    "\n",
    "# define harmony collection\n",
    "collection = Collection(id=earthaccess.search_datasets(doi=doi_atl08,\n",
    "                                   cloud_hosted= True)[0].concept_id())\n",
    "# define harmony request\n",
    "request = Request(collection=collection, \n",
    "              spatial=bounding_box,\n",
    "              ignore_errors=True)\n",
    "\n",
    "# submit harmony request\n",
    "subset_job_id = harmony_client.submit(request)\n",
    "result_atl08 = harmony_client.result_urls(subset_job_id, show_progress=True, \n",
    "                                  link_type=LinkType.s3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e723706-cd0d-4fcc-94ea-98d9be9a133d",
   "metadata": {},
   "source": [
    "### Land Segments\n",
    "ATL08 data are grouped into six ground tracks: `gt1l`, `gt1r`, `gt2l`, `gt2r`, `gt3l`, and `gt3r`. The ground tracks with names ending with `l` are strong beams, and those ending with `r` are weak beam types. The land_segments group within each ground track contains photon data stored as aggregates of 100 meters.\n",
    "\n",
    "Within the `land_segments` group, the geolocation coordinates are provided in `latitude` and `longitude` variables. The variable `n_seg_ph` contains the number of photons in each segment. \n",
    "\n",
    "Let’s read those variables from the subset files and put them into a geopandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5301502-34c6-46ad-90fd-2b55eadc004e",
   "metadata": {},
   "outputs": [],
   "source": [
    "latitude = []\n",
    "longitude = []\n",
    "n_seg_ph = []\n",
    "ph_h = []\n",
    "classed_pc_flag = []\n",
    "chm_50 = []\n",
    "chm_98 = []\n",
    "for s3_url in result_atl08:\n",
    "    with s3.open(s3_url, mode='rb') as fh:\n",
    "        with h5py.File(fh) as hf:\n",
    "            for var in list(hf.keys()):\n",
    "                if var.startswith('gt'):\n",
    "                    latitude.extend(hf[var]['land_segments']['latitude'][:])\n",
    "                    longitude.extend(hf[var]['land_segments']['longitude'][:])\n",
    "                    n_seg_ph.extend(hf[var]['land_segments']['n_seg_ph'][:])\n",
    "                    ph_h.extend(hf[var]['signal_photons']['ph_h'][:])\n",
    "                    classed_pc_flag.extend(hf[var]['signal_photons']['classed_pc_flag'][:])\n",
    "                    chm_98.extend(hf[var]['land_segments']['canopy']['h_canopy'][:])\n",
    "                    chm_v = hf[var]['land_segments']['canopy']['canopy_h_metrics']\n",
    "                    # chm = chm_v[:, 8]\n",
    "                    # chm[chm==chm_v.attrs['_FillValue']] = np.nan\n",
    "                    chm_50.extend(chm_v[:, 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de88de3a-33c4-40e0-bf9f-314ce740ccb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the lists into a dataframe\n",
    "atl08_df = pd.DataFrame(list(zip(latitude,longitude,n_seg_ph)), \n",
    "                    columns=[\"latitude\", \"longitude\", \"n_seg_ph\"])\n",
    "# converting pandas dataframe into geopandas dataframe\n",
    "atl08_gdf = gpd.GeoDataFrame(atl08_df, crs=\"EPSG:4326\",\n",
    "                         geometry=gpd.points_from_xy(atl08_df.longitude, atl08_df.latitude))\n",
    "# print the first two rows\n",
    "atl08_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b5c862-1edc-44b7-b0c5-c6514fd75dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "atl08_gdf.explore(m=m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f738d435-cffe-42a0-a9ac-61647d1a6094",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pandas dataframe\n",
    "atl08_df2 = pd.DataFrame(list(zip(chm_50,chm_98)), columns=[\"chm_50\", \"chm_98\"])\n",
    "# gedi allometry\n",
    "atl08_df2[\"AGBD\"]= -134.77015686035156 + (6.653591632843018 * atl08_df2.chm_50) + (6.687118053436279 * atl08_df2.chm_98) \n",
    "# predictor_offset\n",
    "atl08_df2[\"AGBD\"] = atl08_df2[\"AGBD\"]+100\n",
    "fig = plt.figure(figsize=(15,5))\n",
    "ax1 = fig.add_subplot(1, 3, 1)\n",
    "sns.histplot(ax=ax1, data=total_agb, y=\"AGBD\", binwidth=20, kde=True, stat='percent')\n",
    "ax1.set(ylabel=\"AGBD (Mg / ha)\", ylim=(0, 500),\n",
    "       title=\"Field Plot AGBD estimates\")\n",
    "ax2 = fig.add_subplot(1, 3, 2)\n",
    "sns.histplot(ax=ax2, data=gedi_gdf[mask], binwidth=20, y=\"agbd\", kde=True, stat='percent') \n",
    "ax2.set(ylabel=\"AGBD (Mg / ha)\", ylim=(0, 500),\n",
    "       title=\"GEDI L4A AGBD estimates\")\n",
    "ax3 = fig.add_subplot(1, 3, 3)\n",
    "sns.histplot(ax=ax3, data=atl08_df2, binwidth=20, y=\"AGBD\", kde=True, stat='percent') \n",
    "ax3.set(ylabel=\"AGBD (Mg / ha)\", ylim=(0, 500),\n",
    "       title=\"ICESat-2 ATL08 AGBD estimates\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49befc92-ecd7-41f4-89b7-2de424cc0994",
   "metadata": {},
   "source": [
    "### Photon Classification\n",
    "Photon information is provided in the `signal_photons` group within each ground track. Let’s plot the photon height (`ph_h`) and classification (`classed_pc_flag`) of these four ATL08 files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f07806-fadd-4862-9d9c-fcc12d38b348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# photon classes\n",
    "classes = ['noise', 'ground', 'canopy', 'top_of_canopy']   \n",
    "colors = ListedColormap(['gray','blue','green','red'])\n",
    "plt.figure(figsize=(12, 3))\n",
    "scatter = plt.scatter(range(len(ph_h)),ph_h,c=classed_pc_flag, cmap=colors, s=1)\n",
    "plt.legend(handles=scatter.legend_elements()[0], labels=classes)\n",
    "plt.ylim(-100, 150) \n",
    "plt.ylabel(\"photon height (m)\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "global-global-BioSCape",
   "language": "python",
   "name": "conda-env-global-global-BioSCape-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
